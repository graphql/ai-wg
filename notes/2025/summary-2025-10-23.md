# Meeting Summary for AI WG

**NOTICE**: This summary was auto-generated by Zoom's "AI". AI-generated
content may be inaccurate or misleading. Always check for accuracy. If in
doubt, please consult the meeting recording at
https://youtube.com/@GraphQLFoundation/playlists

- Meeting start: 2025-10-23T17:25:44Z
- Meeting end: 2025-10-23T18:35:29Z
- Summary start: 2025-10-23T17:30:25Z
- Summary end: 2025-10-23T18:33:08Z

The GraphQL working group held its first meeting to establish its foundation and discuss the intersection of GraphQL and AI technologies. The group explored various aspects including service-to-server communication, tooling improvements, and the potential of LLMs in generating and understanding GraphQL queries. They concluded with plans to create benchmark datasets, publish blog posts on different use cases, and continue discussions on GitHub to advance the integration of GraphQL and AI technologies.

## Next Steps

- Jens to write a blog post about GraphQL for server-to-server communication use cases.
- Benjie to provide support and guidance for the blog post writing process.
- kqu and Alexandre to publish the fake schemas  created for LLM benchmarking.
- kqu and Alexandre to publish the set of 16 questions used for benchmarking LLMs on GraphQL query generation.
- Working group members to continue discussions on schema reduction, error handling, and query construction using GitHub issues.

## Summary

### GraphQL Working Group Kickoff

The first meeting of the GraphQL working group was hosted by Koei, who introduced the purpose of the group and outlined the membership agreement and guidelines. Attendees were asked to introduce themselves and explain their reasons for joining the working group, with Koei starting the introductions and passing to Jeff. The meeting focused on establishing the group's foundation and setting expectations for future discussions.

### GraphQL AI Integration Strategies

The GraphQL AI Working Group meeting began with introductions from various members, including Jeff Auriemma from Apollo, Benjie, Michael Staib from ChiliCream, and others representing different companies and backgrounds in GraphQL and AI. The group discussed the synergy between GraphQL and AI, exploring how LLM-powered experiences can complement GraphQL. They also touched on the need for better tooling and best practices for the community. The conversation ended with a reminder about open grants for key initiatives, including AI, and an agenda item on discussing GraphQL for server-to-server communication, with a focus on making it less focused on UI and more suitable for service-to-service interactions.

### GraphQL for Service-to-Service Communication

The team discussed the use of GraphQL for service-to-service communication, particularly in AI products. Mark explained that they are unlocking GraphQL for service-to-service communication to improve authentication and authorization. He also mentioned a blog post by Andre about the "sweet spot" for GraphQL, which suggested that service-to-service communication was not a primary use case. Michael Watson highlighted the importance of UI connection and noted that many backend developers may not be familiar with GraphQL clients. The team agreed to explore why GraphQL is chosen over other options like GRPC for service-to-service communication, with Uri suggesting they look at current practices and LLM-generated code examples.

### GraphQL for Server-to-Server Communication

The team discussed the use of GraphQL for server-to-server communication, with Andrei and Stephen expressing that while GraphQL has advantages for client-to-server interactions, it may not be the best tool for microservice communication due to existing tooling and complexity. Jens highlighted the benefits of Federation, including declarative authorization and improved auditability through schema dependencies. The group agreed to create a series of blog posts to explore different use cases for GraphQL in server-to-server communication, with Jens volunteering to contribute. They also touched on the topic of LLM authorizing GraphQL-related code, though this was not fully explored in the meeting.

### Enhancing LLMs with GraphQL Schemas

The meeting focused on challenges and potential solutions for using Large Language Models (LLMs) with GraphQL schemas. Participants discussed the limitations of LLMs in understanding and generating GraphQL queries, with Pascal noting that leaving the schema for semantic search led to better results. Michael Watson emphasized the need for improvements at the protocol level, suggesting that trusted documents and lifecycle events could enhance query generation. Jerry highlighted the practical challenges of working with large schemas in production, advocating for a more structured approach. The group also touched on the importance of error messages and the need for better documentation that aligns with LLM capabilities. The conversation ended with a suggestion to enable descriptors or hints for LLMs on the schema level to prioritize relevant information.

### GraphQL Query Generation Benchmarking

The working group discussed benchmarking different language models' ability to generate GraphQL queries. Alexandre presented results showing that GPT-4.1, GPT-5, and Claude all performed well, with specific prompts yielding the best results. The team plans to publish a benchmark dataset containing complex schemas and user queries for community evaluation. They aim to validate generated queries against schemas and assess field accuracy. The group agreed to continue discussions on GitHub and to explore non-LLM query construction methods.
