# GraphQL AI WG Meeting Notes - October 2025

**Watch the replays:**
[GraphQL AI WG Meetings on YouTube](https://www.youtube.com/playlist?list=PLP1igyLx8foHcFyh84YcQOfYQ-kNRbPdi)

Agenda:
https://github.com/graphql/ai-wg/blob/main/agendas/2025/10-Oct/23-graphql-ai-wg-october-2025.md

## Notes

- Discussing this document:
  [GraphQL - community idea pad](https://docs.google.com/document/d/1TEBvCZbUUqtcypKanqXv4FWXPp7pZ2ZT9K6Zu4hg5iE/edit)
- GraphQL for service-to-service communication (East-West) - should this be the
  default?
- Should marketing for GraphQL be less focused on UI?
- [Mark] (1) auth is a big reason - facebook style of graph resolvers, thin
  wrapper over endpoints, endpoints do auth close to data egress, normalizes
  things, sign viewer objects, user impersonation as admin. People hack around
  that with auth directive at GraphQL layer
- For us, our internal endpoints didn’t do that. If you have resolvers that do
  auth, in a normalized way, can be called by frontend or another service
- (2) a historic thing - popular blog post from marc-andre: says backend doesnt
  get called
- [Jeff in chat] Principled GraphQL also advises against using GraphQL in this
  manner (service-to-service), and says that Federation is the way to do that
- [Watson] Service-service communication is typically done by backend developers
  – historically, the content isnt there; newer-to-graphql people fall into this
  world and are less likely to use graphql for service to service
- [Kewei] (didn’t catch this - can someone fill in?)
- [Uri] Using GraphQL for agents, other question is for specific types of use
  cases - ask an LLM to bootstrap an app, code, what do they choose to use?
- Look at what they choose to use, and why
- gRPC for example: more efficient transport - GraphQL not tied to transport,
  show GraphQL example. We understand that here, but not a lot of content there.
  I think Jens had a bunch of cool blog posts about that
- Show WHY GraphQL is not tied to the transport.
- [Andrei] \
  (1) is server to server specifically related to AI? Seems like there is already
  a lot of tooling that is hard to compete with – why would someone work with graphql
  when they can use existing tooling. server to server and AI in graphql shouldn’t
  be joined at the hip \
  (2) in graphql, you need to look at the payload etc to figure out what is
  being asked for – this adds a layer of complexity, why would someone want it \
  (3) advantages of graphql don’t seem to translate to server-to-server
- [Stephen] we have a paved path for various things – in service to service, the
  ‘paved path’ [at Netflix] is built around grpc so it doesnt make sense to use
  graphql here. On the one hand, not a lot has been invested into graphql
  tooling yet, so its not used much yet – but once more resources are invested
  it will get better.
- [Mark, in chat] likely a framework issue rather than a spec thing: \
  currently, (most) subgraphs /graphql endpoints expect only to be called by the
  router, and not directy from other services. Middleware needs to now handle this
  dual use case - logging, auth checks, persisted documents etc all need handling.
  \
  To make ^ easier, is there some benefit to standardizing "which type of caller
  you" (encoded via a header or something)?
- [Abhinand, in chat] But wouldn't directly calling the subgraph would lose the
  benefit of Federation?
- [Jens] Customer prefer federated approach with query plan. Helps understand
  cost and which services are being called. Issuing lots of queries is an anti
  pattern, makes it harder to understand. `@requires` directive declares a
  dependency; declarative nature means compliance teams can determine service A
  depends on service B; if field is sensitive, we know this crosses a
  team/service boundary. Federated layer better than calling subgraphs directly.
  Auth logic in resolvers or deeper means it's really hard to determine which
  auth rules are hit by each user agent.
- [Mark, in chat] which leads to another issue: by putting the router in the
  path of lots of service-to-service hops, it starts to look a lot more like
  envoy rather than a standard service. I see some folks have already started to
  deploy the router as a k8s operator, which is a good idea, and a good thing to
  promote as a supported/suggested way of deploying imo
- [Kewei] CTA: Blog post series about server-to-server communication via GraphQL
  use cases
- Action Item: Jens and Mark to collab on a blog post about GraphQL
  service-to-service communication
- [Kewei] Next topic: authorizing GraphQL transactions from LLMs
- Couple of challenges, Thore also presented on this at Conf
- [Thore] Schema discovery - query only for the fields you need, recursively go
  in depth
- How to limit context for how deep to fetch, don’t overload context, balance
  with need for precision
- [Watson] One direction that GraphQL has to go in to survive. Operation
  generation is one side of this, also building graph in general. Resonated in
  audiences outside of GraphQL community: a graph representation of APIs and its
  value in agentic dev. Understanding graph is important. As a community - look
  at all the things that come back (like errors) - rethink them. They are
  written for humans, UIs
- Doing simple things like a validate tool, the errors that come back from that,
  it’s good at fixing things. To Thore’s point - becomes a tool calling loop.
  Something to solve at the protocol level. MCP got to be bc they put lifecycle
  events around GraphQL execution - client event cycles. When connections
  closed, when tools get updated.
- If we got an update on a PQ (trusted document, persisted operation, etc) - we
  gotta do something at the foundation level for schema operations
- [Benjie, in chat] This is why GraphQL's declarative nature is so powerful - we
  can list _all_ the errors in a single request. \
  (Both validation wise, and execution wise.)
- [Pascal] confirm what michael said. We have compared various LLMs and ways of
  doing this. Its surprisingly hard for LLMs to understand it at the moment. The
  only way that it works so far is to do a semantic search – going away from the
  schema was the only thing that worked.
- Generating queries in clients, etc. LLMs are really bad at GraphQL at the
  moment
- [Andrei] Q were trying to ask is how to put together a query thats actually
  valid. It feels like its a thing that an LLM should be able to do pretty well
  – eventually come to a solution as it iterates. Looking at the corpus for an
  LLM, where is a relationship diagram we can leverage so that LLMs understand
  the relationships. This feels like its a client-level concern. On a schema
  level, we need LLMs to know that relationships exist.
- [Kewei] Slump happens when schemas are so large – this happens in production
  envs often.
- [Jerry] Building generic MCP on top of sql. Customers have huge schemas/a lot
  of information in their databases. We came up with a minimal schema – then the
  model can slowly build out the full schema piece by piece. Built a set of
  generic tools that allow customers to describe generic entities. The way the
  schemas are designed today, they will very very quickly exceed token counts in
  the real world. Giant, does-it-all MCP servers are not feasible in real life.
  The schema needs some love. “Find a way to trickle it to the model”
- [Abhinand] GraphQL federated system on backend. Working w MCP server. As
  little context as possible needed so complex instructions for serving one
  after th either as a sequence for agent. Too much data in context when we are
  passing GraphQL schema. Much higher cost than expected. Tried using Apollo MCP
  Server - tried customization. Custom directive for defining a tool for each
  query but could not use multiple agents w/ different descriptions. Tried setup
  using each agent - manually define tool, instructions, what it does, define
  operation file - that’s the compromise we’re doing. Idk if it’s best option -
  that’s the challenge. For some tools, fetch only a few fields, for others,
  other fields. Would be great if agent could be dynamic based on prompt
- [Thore] validate whether query is correct from LLM. Good error description on
  a token-level, issuing which fields went wrong. Structured output for only
  those tokens. Provide additional information on errors with type details if
  helpful to avoid additional introspection calls
- [Jens] (1) Heavily investing into the topic of operations. Problem with
  documentations; descriptions, etc are all written for developers. You need to
  tell more information to an LLM that you don’t need to tell to humans. (2) if
  you have a field on multiple types thats very similar, there may be two paths
  to the same info – the LLM might take the wrong path, but it wouldnt know it
  was wrong. We need to be very careful. Mostly, generating queries is not
  really an LLM problem / its usually the last step.
- [Mark, in chat] our schema, as I the case too I suspect with most non-public
  schemas is: the wild west \
  whilst we strive for a fully normalized deduplicated schema, inevtiably duplications
  sneak in, bad patterns profiliterate, and the core types and root query type gets
  overloaded with too much "juicy" looking fields for agents that get misleading.
  \
  I agree with Jerry ealrier - it's too risky to just give it to the LLM and say
  "go have fun" at runtime. \
  LLMs compiling trusted documents at dev time (which get reviewed)++ \
  (and i'm curious if/how we can improve on that)
- [Troy, in chat] Should we enable some descriptors / hints for llms on schema
  level? So they prioritise the information from there
- [Kewei] main points: schema reduction, query construction
