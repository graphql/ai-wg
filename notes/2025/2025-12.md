# GraphQL AI WG Meeting Notes - December 2025

**Watch the replays:**
[GraphQL AI WG Meetings on YouTube](https://www.youtube.com/playlist?list=PLP1igyLx8foHcFyh84YcQOfYQ-kNRbPdi)

Agenda:
https://github.com/graphql/ai-wg/blob/main/agendas/2025/12-Dec/11-graphql-ai-wg-december-2025.md

### Notes

- Reminder: GraphQL grants
- Thore: shares screen, search to navigate section of a schema
  - Shows vector db
  - Fetches most relevant type/field combos with scoring
  - Essential question: can we improve?
  - Shows recursive iteration over relationships for best matches
  - Kewei: question about blowing up size of db, also do you return top one
  - Thore: enums for instance, use a lot of context. Flattening helps
  - Benefit of returning only fields needed for type
  - Recursive part could be improved. Now just a top one
  - Kewei: how does second iteration look?
  - Thore: first one is based on embedding, then second based on the type
  - Kewei: sometimes returns one, sometimes four, how?
  - Thore: hardcoded, could be other approach
  - Pascal: trying to discover tree to whatever you want down inside of a
    schema, have you tried to do it the other direction? Point based on user
    request, what parts of schema they want, deep inside?
  - Thore: this was bottom-up, then bottom-up toward roots
  - Kewei: your suggestion is to start at Query, Mutation, etc (root type) and
    go down?
  - Pascal: more about pinpointing. If Iâ€™m looking for a user, look for email
    address, etc. Easier to find deeper into schema and go up to root field,
    multiple ways to get there. Input into LLM. Similar to Federation, for
    instance
  - Michael: find shortest path, can catch it pretty fast
  - Pascal: shortest path may not be good for AI though, might be Node,
    userByUsername: need multiple paths, multiple options to present. Makes it
    simple to build a query - a one-hit - do a semantic search, build tree, ask
    LLM what it wants
  - Michael: lookups in composite schemas - similar to what Matt explained about
    identities at Meta (assuming this refers to Matt Mahoney)
  - If we have this data in context, shortest way to this info is by using this
    lookup, different shaped problem. In federation itâ€™s a problem of multiple
    microservices. To not use graph algos all the time, shortest path between
    system cached
  - Pascal (in chat): federation is 100% calculable
  - Thore: just embeddings. More efficient. LLM may write search query but
    thatâ€™s it
  - Pascal: you run into big issues when you have Query and Mutation type, big
    enum fills context
  - Do you index all json?
  - Thore: index on type/field. Just a database
  - Michael: a prime example of schema coordinates
  - Pascal: huge value in having return type
  - Kewei: also wanted to ask this
  - Pascal (in chat): I really like this approach ðŸ‘
  - Thore: (shows csv that maps prompts with metrics: ground_truth_count,
    retrieved, hits, etc.)
  - Kewei: did I overfetch or underfetch?
  - Alexandre: overlaps with my topic
- @require_subschema to introduce gradual reveal of a large schema
  [issue #54](https://github.com/graphql/ai-wg/issues/54) (10m, Hugh)
  - Hugh: (slides)
  - Point of order: _notes will only capture items that are not in the slides_
  - Thore: subschema: build this manually? Or autogenerated?
  - Hugh: started w manually curating, gradually used AI agent internally to
    generate subschema
  - Pascal: size of subschema could also be a problem
  - Kewei: â€œlearningâ€ is a big one - how do you evolve subschema
  - (some missing notes for a few minutes, see recording/transcript)
  - Stephen: subschema is everything reachable from a particular root field
  - Kewei: we prune types, also enum values and input object types
  - Trim down to required, commonly used
  - Dale: solved same problem w different approaches
  - With apollo mcp server, first with search tool, semantic search given
    prompt, try to figure minimum schema amount to run query. That really
    helped. Also did minification system - shorten graphql keyword into one
    letter. Input to i, enum to e, etc. reduce token usage 40%
  - [https://www.apollographql.com/blog/smart-schema-discovery-how-apollo-mcp-server-maximizes-ai-context-efficiency](https://www.apollographql.com/blog/smart-schema-discovery-how-apollo-mcp-server-maximizes-ai-context-efficiency)
- Update on benchmarks introduced in last meeting (5m, Alex)
  - Alex: synthetic schema, user query (what would a user ask for), only want 5
    results, etc
  - Different models, different results (Claude best)
  - Pascal: about generating query string performance? Correct, valid query
    generation
  - Alex: yes, 1:1 match with expected incl. Arguments

Oops, duplicative, sorry about that:

- **Reminder:**
  - GraphQL grants for key initiatives - submit applications if you're
    interested
- **Agenda:**
  - [https://github.com/graphql/ai-wg/blob/main/agendas/2025/12-Dec/11-graphql-ai-wg-december-2025.md](https://github.com/graphql/ai-wg/blob/main/agendas/2025/12-Dec/11-graphql-ai-wg-december-2025.md)
- **Thore Koritzius:**
  - **Topic:** How to find relevant schema elements for queries when you have a
    huge schema.
  - **Approach 1: Flattened approach**
    - Use an off-the-shelf embedding model.
    - **Index by type-field combinations**.
    - Benefit of flattening is to reduce context for types with a large number
      of fields (or enum values).
  - **Approach 2: Recursive Constraint (Improvement on Flattened Approach)**
    - Recursively constrain based on the previous best match.
    - _Example:_ Start with `Query->booking`, use context from `booking:Booking`
      field to search more, then use context from `(Booking.)customer:Customer`
      field to search more.
    - This search happens entirely in the vector database, without using an LLM
      during the search.
  - **Pascal's Idea:**
    - Find a relevant field or fields, and then look for paths from the root to
      that field.
    - Use AI to pick the best path, which helps build a query for the target
      field.
  - **Indexing Details:**
    - Indexing just at the type level was problematic because it's not precise
      enough for large types.
    - They currently index the type-name, field-name, and a comment if
      available.
    - The field's type might not need to be included directly because the
      "recursion" approach incorporates it.
  - **Measurement:**
    - Start with a smaller schema and synthetically generate "golden set"
      query-result pairs.
    - "Blow up" the schema with noisy types and fields.
    - Measure recall and precision based on finding that exact golden set.
- **Hugh Nguyen:**
  - **Use Case:** Agents fetching data using GraphQL.
    - LLM agent generates GraphQL queries based on user intent (e.g., "Get my
      manager's direct reports").
    - _Benefit:_ GraphQL can reduce what would take multiple tool calls (e.g.,
      in MCP 2) into a single query.
  - **Bad Assumption:** More schema $\implies$ better LLM? **NO!**
    - Enterprise GraphQL schemas are too big for the LLM context window.
  - **Dynamic Subschema Loading:**
    - Divide the monolithic schema into small, focused subschemas.
    - Start with a minimal "root" schema (common types + entry points).
    - LLM identifies the domains it needs and loads those subschemas.
    - `@require_subschema` can be put on fields as a hint for what subschema
      would be helpful.
  - **Challenges and Solutions:**
    - _Challenge:_ LLMs often don't follow instructions and want to jump to an
      answer, leading to hallucinated types and fields.
    - _Solutions:_
      - Model training: Bake "subschema loading" into the model.
      - Prefetch subschema based on user intent.
  - **Q&A on Subschemas:**
    - _Q: Did you manually create the subschemas?_
      - _A:_ Initially manual, but switched to having agents do it instead.
    - _Q: Don't the subschemas themselves get too big?_
      - _A:_ They encourage teams to break up schemas into granular pieces. They
        also combine the subschema approach with others and use logs to better
        formulate subschemas.
    - _Q: Do the subschemas include all fields of a type?_
      - _A:_ Yes, they prune fields and enum values.
  - **Other Discussions:**
    - "Normal" introspection is very inefficient; discussed "semantic
      introspection" as a solution.
    - Referenced a post on Apollo MCP server's two approaches: semantic search
      for minimum schema and a "minification"
      system:[ Smart schema discovery: How Apollo MCP server maximizes AI context efficiency](https://www.apollographql.com/blog/smart-schema-discovery-how-apollo-mcp-server-maximizes-ai-context-efficiency).
- **Alexandre Dias:**
  - **Topic:** Measuring how good LLMs are with GraphQL.
  - They have a few benchmark queries.
  - They measure the generated query versus expected benchmark queries.
  - Original measurement was naive and syntactic.
  - Since then, new, more accurate ways to measure have been added, particularly
    "graders" to evaluate queries semantically.
  - Latest results will be published soon.
